# Carl-Louis Van Brandt

Boulevard de la Woluwe 60B-43

Woluwe-Saint-Lambert, Belgium, 1200

+32478969310

<clvanbrandt@gmail.com> | [LinkedIn Profile](https://www.linkedin.com/in/carl-louis-van-brandt-74a9021a2/) | [GitHub Profile](https://github.com/clvanbrandt)

---

## **Summary**

A highly skilled and proactive Senior Data/Cloud Engineer with extensive experience in designing, implementing, and optimizing complex data and cloud architectures. Proven track record in leading technology adoption, modernizing infrastructure, and harmonizing codebase structures across teams to enhance efficiency and stability. Expert in building scalable ETL pipelines, real-time data processing systems, and cloud-based solutions using cutting-edge technologies like Kubernetes, Apache Spark, Delta Lake, and AWS. Adept at fostering knowledge sharing through internal workshops and driving continuous improvement in development processes. Committed to delivering robust, secure, and cost-effective solutions that support business growth and innovation.

---

## **Technical Skills**

- **Cloud Platforms:**
  - _AWS_:
    - API & Serverless: API Gateway, Lambda, DynamoDB, EventBridge, Cloudwatch Logs, X-Ray, S3, Cognito, SQS
    - ETL: Athena, Glue, S3, RDS, Kubernetes (EKS), EMR, ECS, ECR,
      EC2, MWAA
    - IAM & Security: IAM, IAM Identity Center, Cognito, Secrets
      Manager, Parameter Store, KMS
    - Network: VPC, VPC peering, VPN, cross-account communication
    - DevOps: CodePipeline, CodeBuild
    - SysAdmin: SNS, Systems Manager
  - _Azure_: AKS, Active Directory, DevOps, VMs, Data Bricks
  - _Vercel_
- **Programming Languages:** Python, Scala, Rust, HCL, Javascript,
  Typescript, C
- **Databases:** PostgreSQL, DynamoDB, MySQL, SAP Hana, Redis
- **DevOps and CI/CD:** Docker, Kubernetes, Terraform, Github Actions, Azure DevOps
- **Data Engineering:** Apache Airflow, Big Data (Hadoop, Spark, Spark Structured Streaming), Kafka, AWS Kinesis, Delta Lake
- **Monitoring and Logging:** Cloudwatch, Prometheus, FluentBit, Grafana
- **Backend Technologies:** RESTful APIs, Microservices, Serverless Architecture
- **Collaboration and Project Management:** Linear, Jira, Notion, Agile
  methodology
- **Other Tools/Technologies:** Git, Linux, MacOS, Windows, (Neo)Vim, Microsoft Teams, Slack, Discord

---

## **Experience**

### **Data Engineer**

**Jetpack.AI** - Etterbeek, Belgium

September 2019 – Present

- Spearheaded technology discussions and drove the integration and adoption of new tools and practices across the company, becoming the most active advocate for technological advancements.
- Led the initiative to harmonize codebase structures across multiple projects and teams, significantly improving consistency and efficiency. Promoted and integrated DevOps practices and CI/CD processes company-wide.
- Developed a robust ETL framework for Apache Spark applications, abstracting common data processing concepts and enhancing integration with Apache Airflow, which streamlined development processes.
- Modernized an existing ETL pipeline architecture, transitioning from Airflow and Spark on EC2 instances to a multi-AZ Kubernetes solution on AWS EKS. This upgrade drastically reduced failures, enhanced monitoring and developer experience, and improved overall system stability without significant cost increases.
- Designed and implemented a real-time GPS notifications ingestion and analytics system, capable of handling hundreds of notifications per minute, ensuring reliable and timely data processing using DynamoDB and Spark Structured Streaming.
- Architected and maintained multiple ETL pipelines supporting frontend and BI-oriented applications. These pipelines, scheduled at various intervals (from every 15 minutes to monthly), processed diverse datasets including sales, billing, and public infrastructure data. Leveraged Kubernetes (EKS, AKS), AWS EMR, and Apache Airflow for orchestration and execution.
- Engineered an asynchronous system for tracking modifications and newly generated smart meter data using AWS services, including EventBridge, Lambda, SQS, SNS, and dead-letter queues. Designed and implemented the accompanying ETL pipeline that transformed raw data into a versioned standard layer in a data lake using Spark Delta Lake and AWS S3, ensuring data integrity and consistency.
- Suggested, designed, and implemented the company’s Identity and Access Management (IAM) strategy and overall cloud architecture. Advocated for the adoption of IAM Identity Center and a multi-account AWS structure, leading to a more secure and scalable infrastructure managed through Terraform and Infrastructure as Code (IaC) best practices.
- Hosted multiple internal workshops covering various technologies, aiding in the onboarding of new team members and fostering healthy discussions about internal tools and best practices.

---

## **Education**

**Master Degree in Electric Engineering**

Université Catholique de Louvain - Louvain-La-Neuve, Belgium

September 2014 – September 2019

- Relevant coursework: Cryptography, Machine Learning, Computer
  Networks
- Honors/Awards: cum laude

---

## **Certifications**

- **Solution Architect Associate** – AWS
  [2020]
- **Security Specialist** – AWS
  [2021]

---

## **Projects**

### **[Project Name]**

- **Description:** Briefly describe the project, highlighting its purpose and the problem it solved.
- **Technologies Used:** [List the main tools, technologies, and platforms you used]
- **Responsibilities:** [Describe your specific contributions to the project]
- **Outcome:** [What was the result or impact of the project?]

### **[Project Name]**

- **Description:** Briefly describe the project, highlighting its purpose and the problem it solved.
- **Technologies Used:** [List the main tools, technologies, and platforms you used]
- **Responsibilities:** [Describe your specific contributions to the project]
- **Outcome:** [What was the result or impact of the project?]
